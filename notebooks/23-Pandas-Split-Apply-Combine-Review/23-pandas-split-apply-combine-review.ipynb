{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d63a82cb-bb18-4ed2-860c-5c68c971b12e",
   "metadata": {},
   "source": [
    "# Data Analysis with Pandas: split-apply-combine\n",
    "\n",
    "Last week, we learned:\n",
    "- Pandas is a library in Python that is designed for data manipulation and analysis\n",
    "- How to use libraries (import them, access their functions and data structures with `library.function_name()`)\n",
    "- About the `dataframe` data structure: basically a smart spreadsheet, with rows of observations, and columns of variables/data for each observation - sort of a cross between a list (sortable, indexable) and a dictionary (quickly access data by key)\n",
    "- Some basic operations: constructing a dataframe, summarizing, subsetting, reshaping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddfa3be-59c3-45da-9f05-c591747755f5",
   "metadata": {},
   "source": [
    "This week, we'll learn a bit more about summarization:\n",
    "- Use `.value_counts()` to summarize categorical data\n",
    "- Use `.crosstab()` to summarize categorical data cross multiple columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d88412-66fa-44b1-b4bb-69cf5a43342d",
   "metadata": {},
   "source": [
    "And more advanced operations for reshaping/modifying your dataframe:\n",
    "- Use `.apply()` to apply functions to one or more columns to generate new columns\n",
    "- Use `.groupby()` to split your data into subgroups, apply some function to their data, then combine them into a new dataframe for further analysis (the \"**split-apply-combine**\" pattern that is fundamental to data analysis with pandas)\n",
    "- Use some basic plotting functions to explore your data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3bb4f9-dd85-4283-bd64-298ec9c4af3f",
   "metadata": {},
   "source": [
    "I'll then tie it all together to show how they map to problem formulations for your Project 4: all the projects have the same basic structure!\n",
    "\n",
    "These roughly correspond to Qs 6-8 in your PCEs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a2fd02-95a4-4928-8fcc-edb5affc07b5",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "The files we'll be working with in this session are the datasets we're giving for Project 4.\n",
    "\n",
    "You can download them here:\n",
    "* [bls-by-category.csv](https://terpconnect.umd.edu/~gciampag/INST126/data/bls-by-category.csv \"bls-by-category.csv\")\n",
    "* [BreadBasket_DMS.csv](https://terpconnect.umd.edu/~gciampag/INST126/data/BreadBasket_DMS.csv \"BreadBasket_DMS.csv\")\n",
    "* [ncaa-team-data.csv](https://terpconnect.umd.edu/~gciampag/INST126/data/ncaa-team-data.csv \"ncaa-team-data.csv\")\n",
    "* [testudo_fall2020.csv](https://terpconnect.umd.edu/~gciampag/INST126/data/testudo_fall2020.csv \"testudo_fall2020.csv\")\n",
    "\n",
    "<!--\n",
    "Make sure you save them into the _same folder_ as the notebook. In Google Colab, also make sure to upload them to your runtime.\n",
    "\n",
    "<img src=\"https://terpconnect.umd.edu/~gciampag/INST126/images/colab-files.png\" width=\"15%\">\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328104d7-dbc1-49d9-bed5-665640c2f464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "fn = 'testudo_fall2020.csv'\n",
    "\n",
    "# read in the file into a dataframe called courses\n",
    "courses = pd.read_csv(fn)\n",
    "\n",
    "# use the .head() function to show the top 5 rows in the dataframe\n",
    "courses.head(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a2376e-6aae-46d9-a485-e5a2a2f71274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick summary for quantitative data (works on numerical columns only)\n",
    "courses.describe() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d39f0e-ec46-46af-ada7-fbb01acafcf8",
   "metadata": {},
   "source": [
    "## Use `.value_counts()` to summarize categorical data in your dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ec19da-f7a5-4952-882b-88fd0a88f3fc",
   "metadata": {},
   "source": [
    "Another way to get a summary of one or more columns that are *categorical*.\n",
    "\n",
    "The counts correspond to how many time each particular _category_ (a value) appears in the column.\n",
    "\n",
    "Results are sorted in descending order by default.\n",
    "\n",
    "*Hint: this could be useful for Project 4!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9438e94-3fbd-49dd-8385-f137693094ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# access the area column in the courses dataframe\n",
    "area = courses['area']\n",
    "\n",
    "# and apply the value_counts method to that column, which is a series data structure\n",
    "area.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378235b7-0011-4fbe-865e-baaef9d2d370",
   "metadata": {},
   "source": [
    "A Pandas series is like a cross between a dictionary and a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3dbf3d-1046-4089-bd66-f0803390dc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as above but stored in a new variable\n",
    "area_counts = courses['area'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faa659a-7ac4-4d4d-a996-b8d61cd263e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can get value by named key like a dict\n",
    "area_code = \"INST\"\n",
    "print(f\"{area_code}: {area_counts[area_code]}\")\n",
    "\n",
    "# and also by location\n",
    "print(f\"most frequent item count: {area_counts[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653b5e07-080a-441e-a053-123040ee3103",
   "metadata": {},
   "source": [
    "To list all the keys use the `.keys()` method. Returns a pandas object called an \"index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bd62b8-2718-4aff-8b39-f1583a538782",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_counts.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2dbf09-c171-46b2-bdfa-394c6465ff9c",
   "metadata": {},
   "source": [
    "Let's say we want the top 5 most populous areas. We can slice/subset the series just like a list, and then get the keys from that subset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01057c43-b46f-42b1-aa8a-1ddacb929d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a slice (like a list) and then get keys (like a dict)\n",
    "area_counts[:5].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8af54bf-e24c-4fc5-9d45-9230022195e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bread = pd.read_csv('BreadBasket_DMS.csv')\n",
    "\n",
    "# how do we get the frequency counts for items in the bread dataframe?\n",
    "bread['Item'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2143cdc0-3ca7-4b10-ac33-867dfd0fe6dc",
   "metadata": {},
   "source": [
    "## Use `crosstabs()` to summarize categorical data across multiple columns \n",
    "\n",
    "If we have _multiple_ categorical columns, we may want to get the frequency of a particular combination of values from both columns.\n",
    "\n",
    "Let's use the NCAA dataset to show this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288daffd-37f7-43c2-b9e6-3b6403b621ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from CSV\n",
    "ncaa = pd.read_csv(\"ncaa-team-data.csv\")\n",
    "\n",
    "# summarize first 5 rows\n",
    "ncaa.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbd7ade-d77c-431b-b464-be87a94a0c16",
   "metadata": {},
   "source": [
    "Let's explore the `ncaa_result` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5461dc4b-bb72-4e10-ae01-77ff28e880fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All possible results\n",
    "ncaa['ncaa_result'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58fa888-0e64-4c3c-a773-bd7d407ca91d",
   "metadata": {},
   "source": [
    "Let's explore the `coaches` column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39b9234-8596-4242-bf8f-c7fa3a011c8b",
   "metadata": {},
   "source": [
    "We can count how many times each coach had a particular result (column `ncaa_result`).\n",
    "\n",
    "One problem is that coaches can appear with different seasons (if they coached at different schools).\n",
    "\n",
    "So, first, let's clean the `coaches` column to extract only the name without the season part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4469fc6f-ee20-4df8-bf86-bcd44d2ae75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coach_name(x):\n",
    "    \"\"\"\n",
    "    Extract the name of the (first) coach in the season\n",
    "    \"\"\"\n",
    "    # split the string around spaces\n",
    "    try:\n",
    "        elements = x.split(' ')\n",
    "    except AttributeError as er:\n",
    "        elements = ['No', 'Coach']\n",
    "    first_and_last_name = elements[:2]\n",
    "    coach_name = \" \".join(first_and_last_name)\n",
    "    return coach_name\n",
    "\n",
    "# apply get_coach_name function to each entry in column `coaches` and create new column `coach_name`\n",
    "ncaa['coach_name'] = ncaa['coaches'].apply(get_coach_name)\n",
    "ncaa\n",
    "# create a sub-dataframe with just two columns -- ncaa_result and coach_name\n",
    "sub_ncaa = ncaa[['coach_name', 'ncaa_result']]\n",
    "sub_ncaa.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f408d32-4d94-4e4f-836d-8695284386aa",
   "metadata": {},
   "source": [
    "This however gives me a series and not a dataframe.\n",
    "\n",
    "The `crosstab` function instead organizes the same data in a tabular format (so as a dataframe instead of a series).\n",
    "\n",
    "We can ask who are the people who won _some_ national finals but also lost _some_ regional finals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06859121-9f1f-4c3b-bbb3-f158ee0890fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "coach_results = pd.crosstab(ncaa['coach_name'], ncaa['ncaa_result'])\n",
    "\n",
    "coach_results[(coach_results[\"Won National Final\"] > 0) & (coach_results['Lost Regional Final'] > 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d1ec56-aef0-45b5-983b-268eb9a5f68e",
   "metadata": {},
   "source": [
    "Can do the same with the UMD courses data. Let's see how many areas offer introductory courses.\n",
    "\n",
    "To decide whether a course is an &ldquo;introductory&rdquo; we can check if it has the string `\"Introduction\"` in the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f16b35b-adb2-4fad-9619-37c39884e93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_intro(title):\n",
    "    \"\"\" \n",
    "    Determine whether a course title has the word \"Introduction\" or not in it\n",
    "    \"\"\"\n",
    "    if \"Introduction\" in title:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# apply the is_intro function to the title column in courses\n",
    "# and save the results in the is_intro column in courses\n",
    "courses['is_intro'] = courses['title'].apply(is_intro)\n",
    "\n",
    "# show me the top 5 rows in the dataframe\n",
    "courses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989ac615-cb1f-4752-b4af-643872564d49",
   "metadata": {},
   "source": [
    "Now use `.crosstab()` method to cross-tabulate the counts across columns `area` and `is_intro`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdec458d-777c-4e48-99fa-3f609cfaeaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-tabulate area and is_intro\n",
    "intro_by_area = pd.crosstab(courses[\"area\"], courses[\"is_intro\"])\n",
    "intro_by_area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d0b579-a219-4484-8f7f-7460ead4cebd",
   "metadata": {},
   "source": [
    "Notice that `.crosstab()` works with numerical data too. \n",
    "\n",
    "But the column names in the new data frame (`0` and `1`) are not very meaningful. \n",
    "\n",
    "We can rename them with `.rename()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4338bf-9d7a-4faf-b493-3d8ecd0d16c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names = {\n",
    "    True: \"Yes\",\n",
    "    False: \"No\"\n",
    "}\n",
    "intro_by_area = intro_by_area.rename(columns=new_names)\n",
    "intro_by_area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b41b1ca-95fa-4999-85eb-8e0dba668abf",
   "metadata": {},
   "source": [
    "Now compute the fraction of intro courses per area. This is:\n",
    "\n",
    "$$\n",
    "\\frac{\\rm yes}{({\\rm yes} + {\\rm no})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719b1010-9131-4018-bf20-a03b5c6f39c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "intro_by_area['frac_intro'] = intro_by_area['Yes'] / (intro_by_area['Yes'] + intro_by_area['No'])\n",
    "intro_by_area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4db80e-3eb1-4da6-b39a-c4dff06de36f",
   "metadata": {},
   "source": [
    "Reset index if you want the `area` information to be usable for analysis/plotting/etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1884c59c-da02-4758-b3fa-4b18bd7f30b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "intro_by_area = intro_by_area.reset_index()\n",
    "intro_by_area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fbc7c9-b69c-4c79-bbe3-677ab21ea52e",
   "metadata": {},
   "source": [
    "## Computing data based on one or more columns using `.apply()`\n",
    "\n",
    "All these examples involved modifying or creating new columns!\n",
    "\n",
    "In data analysis, we often want to do things to data in our columns for data preparation/cleaning. \n",
    "\n",
    "Sometimes there is missing data we want to re-code, or there is data we want to re-describe or re-classify for our analysis. \n",
    "\n",
    "We can do this with a combination of functions and the `apply()` method. It comes in two flavors:\n",
    "\n",
    "- With a single column (i.e. on a Series)\n",
    "- With multiple columns (i.e. on a DataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af2b20c-d3cb-4971-b366-b323a2637135",
   "metadata": {},
   "source": [
    "### `.apply()` with a single column\n",
    "\n",
    "The `prereqs` column gives a string description of the prerequisites for the course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c467452-cc6a-4eba-b761-c2bee02d54f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "courses['prereqs'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6921e48a-bc16-488a-8791-9134a7b15c53",
   "metadata": {},
   "source": [
    "Let's say we want to have a `prereqs` column that is sortable. For example:\n",
    "\n",
    "    0 = No prereqs \n",
    "    1 = has prereqs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fad1f58-90e0-46ae-92d3-62403566ef9b",
   "metadata": {},
   "source": [
    "#### Step 1: Define the function you want to apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6222208-bcd2-4e66-b9ca-07c38f17e535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: define the function you want to apply\n",
    "def has_prereq(prereq_descr):\n",
    "    \"\"\"\n",
    "    Determine whether a pre-requisite description includes the string \"None\"\n",
    "    \"\"\"\n",
    "    if \"None\" in prereq_descr:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb744dd-34bd-40a7-8fd6-c01f460123e7",
   "metadata": {},
   "source": [
    "Test the function on some sample inputs to check it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2d105a-7fe1-4210-b39f-e02d45943bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this should yield 1\n",
    "prereq = \"BMGT301; or instructor permission\" \n",
    "print(f\"With {prereq=!r}: {has_prereq(prereq)=}\")\n",
    "\n",
    "# this should yield 0\n",
    "prereq = \"None\"\n",
    "print(f\"With {prereq=!r}: {has_prereq(prereq)=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d35a61-bd3f-46c4-a3e6-27a351c78828",
   "metadata": {},
   "source": [
    "#### Step 2: Apply the function to a column\n",
    "\n",
    "We can create a new column called `has_prereqs` to save this information in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339acda2-1ceb-4d5f-8c55-b2b404e3ad44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: apply it to one or more columns\n",
    "\n",
    "# This applies the has_prereq() function to every row in the prereqs column in the courses data frame\n",
    "courses['has_prereqs'] = courses['prereqs'].apply(has_prereq) \n",
    "courses.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce59cfdb-786b-4b0f-8dc8-43f1018f3017",
   "metadata": {},
   "source": [
    "We can crosstab the new column with the previous `is_intro` column to see how many introductory courses have pre-requisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3617748e-75ee-4f57-9cec-407c25416e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(courses['is_intro'], courses['has_prereqs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634ed98e-2532-4718-acc4-b98ad9f11d4d",
   "metadata": {},
   "source": [
    "Interestingly, some courses that are called `\"Introduction ...\"` do have pre-requisites. \n",
    "\n",
    "We can use boolean indexing (in the o to see what are these courses!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e7f678-01d4-4549-b995-cca302bb8c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "courses[(courses['is_intro'] == True) & (courses['has_prereqs'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02837457-0df9-4e33-9cd6-6e50ea5d5a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_intro(descr):\n",
    "    if \"intro\" in descr.lower():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "courses['has_intro'] = courses['description'].apply(has_intro)\n",
    "courses.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eed6ec7-bca1-4197-a837-847f95b27120",
   "metadata": {},
   "source": [
    "#### What's happening under the hood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b18130-f1d4-435d-b2db-8764e880751a",
   "metadata": {},
   "source": [
    "As another example, let's say I want to know how many courses of each level (100-, 200-, 300-level, etc.) we have in each area. We don't have that data in the dataset; at least not explicitly. Fortunately we can make it with some simple programming that you already know how to do! The problem here is, given a code (i.e., data from one column), how do we \"extract\" the area?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4aab96-aca7-439d-a0bc-0c79c19b644f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: define the function\n",
    "def extract_level(code):\n",
    "    \"\"\"\n",
    "    Given a course code (e.g. INST126) extract the course level (100)\n",
    "    \n",
    "    Note that this function assumes course code starts with 4-letter area\n",
    "    \"\"\"\n",
    "    return code[4] + '00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c01ccb-2c0d-460b-83c2-32b3fbe84847",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = \"CMSC250\"\n",
    "extract_level(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e3b5c4-5aba-4592-9cf9-7b8d6804d2c4",
   "metadata": {},
   "source": [
    "Let's see how this works!\n",
    "\n",
    "The `.apply()` function generates a list that is the same length as the input column's number of rows, with a corresponding value for each input \n",
    "\n",
    "(in this case, we have 414 rows in the data frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f045e9-f6e0-4921-b6d1-ed63c7570847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: apply the function\n",
    "courses['level'] = courses['code'].apply(extract_level)\n",
    "courses.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973d880a-1ac6-4c55-9b00-9c807bf96914",
   "metadata": {},
   "source": [
    "This is equivalent to calling `extract_level` repeatedly in a for loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb29271-5318-4bfb-8faf-084d947575ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = []\n",
    "for i in range(len(courses)):\n",
    "    row = courses.loc[i]\n",
    "    code = row['code']\n",
    "    level = extract_level(code)\n",
    "    print(f\"{i}: code={code}, level={level}\")\n",
    "    tmp.append(level)\n",
    "courses['level'] = tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5be5c57-5868-4373-ae72-762f2426a945",
   "metadata": {},
   "source": [
    "Another example with the bread basket data frame. \n",
    "\n",
    "Let's extract the hour of the day from the `Time` column and save it in a column called `Hour`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c67433-47f4-4584-90da-852d38766ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hour(time):\n",
    "    return int(time.split(\":\")[0])\n",
    "\n",
    "bread['Hour'] = bread['Time'].apply(extract_hour)\n",
    "bread.sort_values(by=\"Hour\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d2db7d-8774-41dd-b245-69a88320f473",
   "metadata": {},
   "source": [
    "#### Step 3: Save the resulting data from the `.apply()` into a new / existing column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aec955a-fcf4-4efe-9328-73d9e32bf296",
   "metadata": {},
   "source": [
    "What if we want to save the results so we can use it later? We can simply assign it to a column, new or existing. \n",
    "\n",
    "Remember, pandas prefers immutability in general (return a new object instead of modifying the object), and sometimes enforces it. \n",
    "\n",
    "With `.apply()`, it's enforced: you can't do it in place, you have to assign the returned series to a new variable if you want it to persist. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a014d1-a80c-4258-851e-8262872f71c1",
   "metadata": {},
   "source": [
    "### `.apply()` with data from multiple columns\n",
    "\n",
    "What if you want to have a way to filter the courses in terms of \"easy entry points\" (i.e., both introductory *and* has no prerequisites)? \n",
    "\n",
    "That might also be interesting to analyze by area to see how many departments offer these easy entry points into the department for students from other departments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cf7e44-384a-4942-91bf-fc1475b0c791",
   "metadata": {},
   "source": [
    "Core thing we need to know here is that our `.apply()` will now apply a function that has a **row** as input, not an element of a single column. \n",
    "\n",
    "That way, we can access data from any column in the row: in this case, data from the `is_intro` and `has_prereq` columns.\n",
    "\n",
    "We tell `.apply()` to do this with the `axis` parameter. \n",
    "\n",
    "We need to pass `axis=1` when we call `.apply()` so it knows to pass a row into the function, not just a single column element. \n",
    "\n",
    "See here for more details: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.apply.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07a4ac1-12c9-4735-b4f5-f9f308c5de2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_entry_point function\n",
    "def is_entry_point(row):\n",
    "    \"\"\"\n",
    "    Determine whether a course is an \"entry point\" based on these two conditions:\n",
    "    - It is an \"intro\" course (is_intro = 1)\n",
    "    - It has no prerequisites (has_prere = 1)\n",
    "    \"\"\"\n",
    "    if row['is_intro'] == 1 and row['has_prereqs'] == 0: \n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5e6781-1558-4580-a058-c0526331937d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this should yield 1\n",
    "test_row = {\n",
    "    'is_intro': 1,\n",
    "    'has_prereqs': 0\n",
    "}\n",
    "print(f\"With test_row = {test_row} is_entry_point(test_row) = {is_entry_point(test_row)}\")\n",
    "      \n",
    "# this should yield 0\n",
    "test_row = {\n",
    "    'is_intro': 1,\n",
    "    'has_prereqs': 1\n",
    "}\n",
    "\n",
    "print(f\"With test_row = {test_row} is_entry_point(test_row) = {is_entry_point(test_row)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc7d597-6d19-4e31-b3a6-8d97af5bcb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 apply the function (to the whole data frame!) and save the result\n",
    "\n",
    "# need to specify axis=1 to apply it to every row\n",
    "courses['is_entrypoint'] = courses.apply(is_entry_point, axis=1) \n",
    "courses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2fcc7e-9c63-48b5-b04a-2fb72d0db51f",
   "metadata": {},
   "source": [
    "What courses are entry points?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47d431a-17ca-434f-9e03-a25d1f5c9132",
   "metadata": {},
   "outputs": [],
   "source": [
    "courses[courses['is_entrypoint'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18602c9f-7178-4db9-9b3f-f503ce874012",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "majors = pd.crosstab(courses['area'], courses['is_entrypoint'])\n",
    "majors['frac_entry_points'] = majors[1] / (majors[0] + majors[1])\n",
    "majors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc90268-b714-426c-9fb7-e37e675fdf98",
   "metadata": {},
   "source": [
    "## The split-apply-combine pattern (with `.groupby()`)\n",
    "\n",
    "We have seen we can &ldquo;reshape&rdquo; a dataframe in various ways: sorting, summarizing, cross-tabulation, etc.\n",
    "\n",
    "Going more deeply on this path of &ldquo;reshaping&rdquo;, we often __want to compute data based on subsets of the data, grouped by some column__.\n",
    "\n",
    "For example, we might want to see how many departments offer &ldquo;easy&rdquo; entry point courses. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f644532-34fd-413a-a933-85743728934e",
   "metadata": {},
   "source": [
    "We can do this with the \"split-apply-combine\" pattern, which is implemented in the `.groupby()` function.\n",
    "\n",
    "Basically, it goes like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becaca9e-d7c5-4fa6-96ef-97d2f37ed7ec",
   "metadata": {},
   "source": [
    "1. **Split** the data into subgroups (e.g., split courses into department subgroups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b705eb-4b82-4097-b4fb-b997a353429e",
   "metadata": {},
   "source": [
    "2. **Apply** some computation on each subgroup (e.g., find number of easy entry points for each department subgroup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdccc567-cf55-40ac-877d-c6798f48dfd9",
   "metadata": {},
   "source": [
    "3. **Combine** subgroup-computation information into an overall new dataframe that has subgroups as entries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9635af-db1c-468b-a41c-c278ca7271aa",
   "metadata": {},
   "source": [
    "\n",
    "More info in this tutorial https://pandas.pydata.org/docs/getting_started/intro_tutorials/06_calculate_statistics.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d89fb7-8cc8-4fc0-a26d-3058eaf9b794",
   "metadata": {},
   "source": [
    "### 1. Split \n",
    "\n",
    "We use the `.groupby()` method to split a dataframe into subgroups based on the values of a column\n",
    "\n",
    "Let's split the courses dataframe by area and see how many courses are in each split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243a6b1e-53d9-4a9b-a104-20c24f372a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The total number of rows in the data frame\n",
    "print(f\"There are {len(courses)} rows in the data frame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d11df2-ad2d-4de2-b789-d9b65e283525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we print the rows in each split\n",
    "for area, area_courses in courses.groupby('area'):\n",
    "    print(f\"There are {len(area_courses)} rows in the data frame for area = {area}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d29f4c6-841f-42b0-8beb-77e5f4b07a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the split from the last iteration of the loop: it is a dataframe (notice the area column)\n",
    "area_courses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32804372-8e78-404e-bd37-f7f7e525812a",
   "metadata": {},
   "source": [
    "#### Split the manual way\n",
    "\n",
    "We use indexing to find subgroups of rows with a given value, then we can apply some summarization statistics, like the average credits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85de7bb2-27ea-4b4c-8fdd-46a19bc358b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the unique area values\n",
    "course_areas = courses['area'].value_counts().keys()\n",
    "\n",
    "# iterate through each unique area value\n",
    "for area in course_areas:\n",
    "    # get the subset of the course data that is associated with this area\n",
    "    area_courses = courses[courses['area'] == area]\n",
    "    \n",
    "    # print the number of rows\n",
    "    print(f\"There are {len(area_courses)} rows in the data frame for area = {area}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de4bdfb-5e42-4e49-959c-84cbec9ab650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the split from the last iteration of the loop: it is a dataframe (notice the area column)\n",
    "area_courses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6adf6d3-d9e9-4178-8df1-8265dad8fb74",
   "metadata": {},
   "source": [
    "Notice also that these numbers correspond to the output of `courses['area'].value_counts()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb1eb2a-0b01-4049-81f3-0e25cdfe0573",
   "metadata": {},
   "outputs": [],
   "source": [
    "courses['area'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f73ada-977e-44f5-aca6-b33d34ca4366",
   "metadata": {},
   "source": [
    "### Properties of `.groupby()`\n",
    "\n",
    "In general `.groupby()` returns an object of class `DataFrameGroupBy` that performs the split.\n",
    "\n",
    "We use this object to split the courses df into subsets grouped by area. \n",
    "\n",
    "The data frame is first sorted by the column with the groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4477d4-a7ef-430b-8de1-4f92a95d4ce3",
   "metadata": {},
   "source": [
    "The object also works as an _iterator_: we can iterate through the resulting collection of dataframe subsets where each step in the iteration allows us to grab:\n",
    "1. the name of the subset, which is the shared value (in this case area)\n",
    "2. the subset dataframe (here called `area_courses`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6633cb43-7c64-4476-acb8-d83d3acf05b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "courses.groupby('area')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a519cfe-5acc-4091-9ecd-84fe0ba71347",
   "metadata": {},
   "source": [
    "On top of supporting iteration, objects returned by `.groupby()` also give you a number of methods/attributes:\n",
    "\n",
    "- `.groupby(...).get(KEY)` &ndash; (_method_) returns the group associated to KEY\n",
    "- `.groupby(...).ngroups` &ndash; (_attribute_) the number of groups\n",
    "- `.groupby(...).groups` &ndash; (_attribute_) a dictionary whose keys are group names and the values the list of corresponding row indices. \n",
    "\n",
    "Here `...` represents the column with the groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31079249-c1f9-4b47-b8a9-c773ab2cab0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = courses.groupby('area')\n",
    "\n",
    "grouped.get_group('INST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725c83c1-1840-4b0e-824c-3b534d8052c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.get_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6d2377-a054-4847-9cdf-ced7bd009f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.ngroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5abf58-95f6-4119-84a1-ad5fe4b0d251",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.groups['INST']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50495366-8a6d-47c9-b845-38eb1f4e9f75",
   "metadata": {},
   "source": [
    "So yet another way to split the dataframe in groups is to use the `.groups` dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a09376-0f65-4a19-967c-2ad854cc4bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = courses.groupby('area')\n",
    "for area in grouped.groups:\n",
    "    idx = grouped.groups[area]  # <--- list of indices of the rows in this area\n",
    "    area_df = courses.loc[idx]  # <--- need to pass list of indices to the .loc[] indexer\n",
    "    print(f\"There are {len(area_courses)} rows in the data frame for area = {area}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c424b16-ed81-4819-92fa-002c95517e71",
   "metadata": {},
   "source": [
    "### 2. Apply and Combine\n",
    "\n",
    "The \"manual\" way: apply and combine into a new dataframe we construct from scratch.\n",
    "\n",
    "First, let's recreate the three columns we built last time using `.apply()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a7fd2b-916b-45a4-81d8-9e009280e779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isintro(title):\n",
    "    return 'Introduction' in title\n",
    "\n",
    "courses['is_intro'] = courses['title'].apply(isintro)\n",
    "\n",
    "\n",
    "def hasprereqs(description):\n",
    "    return 'None' in description\n",
    "\n",
    "courses['has_prereqs'] = courses['prereqs'].apply(hasprereqs)\n",
    "\n",
    "\n",
    "def isentrypoint(row):\n",
    "    if row['is_intro'] == 1 & row['has_prereqs'] == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "courses['is_entrypoint'] = courses.apply(isentrypoint, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf48aaf-aae6-4492-ad9e-94f7049eb382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty list to hold the new rows of the new COMBINED dataframe\n",
    "tmp = []\n",
    "\n",
    "# SPLIT the dataframe by area, and iterate through each split\n",
    "for area, areaData in courses.groupby('area'): \n",
    "  \n",
    "    # APPLY operations on the dataframe split\n",
    "    # ---------------------------------------\n",
    "    \n",
    "    # count the number of entry point courses in the subarea\n",
    "    num_entrypoints = areaData['is_entrypoint'].sum()\n",
    "    \n",
    "    # count the number of total courses in the subarea\n",
    "    num_classes = len(areaData)\n",
    "    \n",
    "\n",
    "    # COMBINE the resulting subcomputation into a new dataset\n",
    "    # -------------------------------------------------------\n",
    "    entry = {\n",
    "      'area': area, # each row is an area\n",
    "      'num_entrypoints': num_entrypoints, \n",
    "      'num_classes': num_classes,\n",
    "    }\n",
    "    tmp.append(entry) \n",
    "    \n",
    "# convert the list of new entries into a dataframe\n",
    "entry_courses_by_area = pd.DataFrame(tmp)\n",
    "entry_courses_by_area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d19603-d46a-4388-81f8-de22da5b6065",
   "metadata": {},
   "source": [
    "Another example: what is busiest hour of the day at the restaurant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102c7345-bd7d-440e-b832-c0e3ba214cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2207ebbe-6a82-46d9-b7ca-eb35cb0dbaa0",
   "metadata": {},
   "source": [
    "First, we use `.apply()` again to extract the hour of the transaction from the `Time` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3af461b-196c-464b-b142-f22d875d32e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gethour(time):\n",
    "    return int(time.split(\":\")[0])\n",
    "\n",
    "bread['hour'] = bread['Time'].apply(gethour)\n",
    "bread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dde8983-9a33-4603-b59a-d0f4eccb5cd2",
   "metadata": {},
   "source": [
    "The use split-apply-combine pattern again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6029b470-579a-4987-9cf8-32afaf2a5833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty list to hold the new rows of the new COMBINED dataframe\n",
    "tmp = []\n",
    "\n",
    "# SPLIT the dataframe by area, and iterate through each split\n",
    "for hour, hour_df in bread.groupby('hour'):\n",
    "  \n",
    "    # APPLY operations on the dataframe split\n",
    "    # ---------------------------------------\n",
    "    \n",
    "    # count the number of entry point courses in the subarea\n",
    "    num_transactions = len(hour_df)    \n",
    "\n",
    "    # COMBINE the resulting subcomputation into a new dataset\n",
    "    # -------------------------------------------------------\n",
    "    entry = {\n",
    "      'hour': hour, # each row is an hour\n",
    "      'num_transactions': num_transactions, \n",
    "    }\n",
    "    tmp.append(entry) \n",
    "    \n",
    "# convert the list of new entries into a dataframe\n",
    "transactions_by_hour = pd.DataFrame(tmp)\n",
    "transactions_by_hour    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62439340-6d67-478f-8628-5f1f41f801b1",
   "metadata": {},
   "source": [
    "#### Named aggregation: Shortcut apply-combine with `.groupby()` + `.agg()`\n",
    "\n",
    "To make `.groupby()` more powerful, we tack on the `.agg()` function to it to tell pandas to *aggregate* particular columns in particular ways (e.g., count the number of entry point courses in a given department, vs. give an average *proportion* of classes that are entry points).\n",
    "\n",
    "this is also called [named aggregation](https://pandas.pydata.org/docs/user_guide/groupby.html#named-aggregation) in the pandas official documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef141ee-5d09-4997-95c0-00c487f12c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT by area\n",
    "courses.groupby(\"area\", as_index=False).agg(\n",
    "    # APPLY these computations and COMBINE into a new data frame using .agg\n",
    "    # ----------------------------------------------------------------------\n",
    "\n",
    "    # 1: apply `.sum()` to the `is_entrypoint` column of each subgroup\n",
    "    num_entrypoints=('is_entrypoint', \"sum\"), \n",
    "    # 2: apply `.count() to the `area` column of each subgroup (similar to taking len() of subgroup)\n",
    "    num_classes=('area', \"count\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8b25ac-7bf9-4f8b-b223-aa6be23b3781",
   "metadata": {},
   "source": [
    "Same with restaurant transactions data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7c70ab-20de-4b10-8f8d-993067f462e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bread.groupby(\"hour\", as_index=False).agg(\n",
    "    num_transactions=(\"Time\", \"count\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3816aaa-2614-4aa9-905c-285af6e42df2",
   "metadata": {},
   "source": [
    "Named aggregations is a relatively newer feature in Pandas. \n",
    "\n",
    "The old school method is much more convoluted. You may still see if sometimes on StackOverflow or other websites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f9681a-71cb-4330-b9de-cd44c5567eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bread.groupby(\"hour\", as_index=False)[['Time']].count().rename(columns={'Time': 'num_transactions'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282b095d-1193-40da-a08c-3c61472e66a9",
   "metadata": {},
   "source": [
    "## Anatomy of combining `.groupby()` with `.agg()` via named aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ad3c32-15aa-43d7-ba97-e608427a3a2a",
   "metadata": {},
   "source": [
    "<img src=\"https://terpconnect.umd.edu/~gciampag/INST126/images/groupby.png\" width=\"100%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2d8ca8-8e64-4505-ae8c-deaadd96c61e",
   "metadata": {},
   "source": [
    "### Using groupby for further analysis\n",
    "\n",
    "Sometimes we want to take the result of the split-apply-combined data frame and do further analysis on it.\n",
    "\n",
    "Recall we said an entry point course (introduction + no prereqs) is an &ldquo;easy&rdquo; to get a sense of what an area is like. \n",
    "\n",
    "Areas with more entry points are more &ldquo;open&rdquo; to people wishing to change major for example.\n",
    "\n",
    "What areas are more open?\n",
    "\n",
    "Now that we now how may entry points courses are there per area, and also how many courses in total there are, we could compute an &ldquo;openness&rdquo; score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e327a875-c25d-40a9-ae26-1755ab9e2710",
   "metadata": {},
   "source": [
    "Here is the aggregated data frame we built before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8374f14-860a-4454-a7aa-f99793def5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_courses_by_area = courses.groupby(\"area\", as_index=False).agg(\n",
    "    num_entrypoints=('is_entrypoint', \"sum\"), \n",
    "    num_classes=('area', \"count\")\n",
    ")\n",
    "entry_courses_by_area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e710b2c-e131-48e0-8c0c-1bd3f89b9947",
   "metadata": {},
   "source": [
    "Let's now compute the proportion of entry point classes, as a proxy for &ldquo;openness&rdquo;, and finally let's sort by that score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6ce9ca-3d3f-4e53-8f5d-0f9626228730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: define the function\n",
    "def openness(row):\n",
    "    return row['num_entrypoints'] / row['num_classes']\n",
    "\n",
    "# step 2: apply the function and save the results\n",
    "entry_courses_by_area['openness'] = entry_courses_by_area.apply(openness, axis=1)\n",
    "\n",
    "# step 3: sort by openness and reset index (passing ignore_index=True argument)\n",
    "entry_courses_by_area.sort_values(by=\"openness\", ascending=False, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6fc8e8-5dea-488d-8ea5-b1cd9c1a14d5",
   "metadata": {},
   "source": [
    "### What can you aggregate?\n",
    "\n",
    "<table class=\"colwidths-given table\">\n",
    "<colgroup>\n",
    "<col style=\"width: 20%\">\n",
    "<col style=\"width: 80%\">\n",
    "</colgroup>\n",
    "<thead>\n",
    "<tr class=\"row-odd\"><th class=\"head\"><p>Function</p></th>\n",
    "<th class=\"head\"><p>Description</p></th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr class=\"row-even\"><td><p><code class=\"xref py py-meth docutils literal notranslate\"><span class=\"pre\">mean()</span></code></p></td>\n",
    "<td><p>Compute mean of groups</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p><code class=\"xref py py-meth docutils literal notranslate\"><span class=\"pre\">sum()</span></code></p></td>\n",
    "<td><p>Compute sum of group values</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p><code class=\"xref py py-meth docutils literal notranslate\"><span class=\"pre\">size()</span></code></p></td>\n",
    "<td><p>Compute group sizes</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p><code class=\"xref py py-meth docutils literal notranslate\"><span class=\"pre\">count()</span></code></p></td>\n",
    "<td><p>Compute count of group</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p><code class=\"xref py py-meth docutils literal notranslate\"><span class=\"pre\">std()</span></code></p></td>\n",
    "<td><p>Standard deviation of groups</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p><code class=\"xref py py-meth docutils literal notranslate\"><span class=\"pre\">var()</span></code></p></td>\n",
    "<td><p>Compute variance of groups</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p><code class=\"xref py py-meth docutils literal notranslate\"><span class=\"pre\">sem()</span></code></p></td>\n",
    "<td><p>Standard error of the mean of groups</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p><code class=\"xref py py-meth docutils literal notranslate\"><span class=\"pre\">describe()</span></code></p></td>\n",
    "<td><p>Generates descriptive statistics</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p><code class=\"xref py py-meth docutils literal notranslate\"><span class=\"pre\">first()</span></code></p></td>\n",
    "<td><p>Compute first of group values</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p><code class=\"xref py py-meth docutils literal notranslate\"><span class=\"pre\">last()</span></code></p></td>\n",
    "<td><p>Compute last of group values</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p><code class=\"xref py py-meth docutils literal notranslate\"><span class=\"pre\">nth()</span></code></p></td>\n",
    "<td><p>Take nth value, or a subset if n is a list</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p><code class=\"xref py py-meth docutils literal notranslate\"><span class=\"pre\">min()</span></code></p></td>\n",
    "<td><p>Compute min of group values</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p><code class=\"xref py py-meth docutils literal notranslate\"><span class=\"pre\">max()</span></code></p></td>\n",
    "<td><p>Compute max of group values</p></td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07e24e0-cd18-4a66-8727-b15417f44686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getname(coaches):\n",
    "    try:\n",
    "        return \" \".join(coaches.split(\" \")[:2])\n",
    "    except AttributeError:\n",
    "        return \"No Coach\"\n",
    "\n",
    "ncaa['coach'] = ncaa['coaches'].apply(getname)\n",
    "\n",
    "ncaa.groupby('coach', as_index=False).agg(\n",
    "    best_wl=('wl', 'max')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811e4a99-8a67-4c7d-be7a-a8230aab5c32",
   "metadata": {},
   "source": [
    "# Putting it all together\n",
    "\n",
    "<img src=\"https://terpconnect.umd.edu/~gciampag/INST126/images/putting-together.png\" width=\"100%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df42ab9-5059-4273-9ed7-fc20586945da",
   "metadata": {},
   "source": [
    "## Reminder: More resources\n",
    "\n",
    "The pandas website is decent place to start: https://pandas.pydata.org/\n",
    "\n",
    "This \"cheat sheet\" is also a really helpful guide to more common operations that you may run into later: https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf\n",
    "\n",
    "There are also many blogs that are helpful, like towardsdatascience.com\n",
    "\n",
    "The cool thing about pandas and data analysis in python is that many people share notebooks that you can inspect / learn from / adapt code for your own projects (just like mine!)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6572c14-ba32-4a93-bc2e-fbcf49839379",
   "metadata": {},
   "source": [
    "## EXTRA: Plotting\n",
    "\n",
    "The main library for plotting in Python is `matplotlib`. You can learn that library later. It has lots of fine-grained controls.\n",
    "\n",
    "For now, you can use pandas \"wrapper\" over matplotlib (basically calling matplotlib from inside pandas), which is a bit easier to learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d2df68-7594-4ac4-a143-380373eb6a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot openness by area\n",
    "entry_courses_by_area.sort_values(by='openness', ascending=False).plot(\n",
    "    x=\"area\", \n",
    "    y=\"openness\", \n",
    "    kind='bar', \n",
    "    xlabel=\"Major\", \n",
    "    ylabel=\"Proportion of entry point classes\",\n",
    "    title=\"Average openness by major\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d9c039-55b2-4094-8c86-1c39707c088a",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_courses_by_area.sort_values(by=\"num_classes\", ascending=False).plot(\n",
    "    x=\"area\", \n",
    "    y=\"num_classes\", \n",
    "    kind=\"bar\",\n",
    "    xlabel=\"Major\",\n",
    "    ylabel=\"Number of classes\",\n",
    "    title=\"Number of courses by major\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f03e69b-2610-4ebb-ba58-8c8870d5d1c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
